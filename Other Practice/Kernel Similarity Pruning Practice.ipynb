{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def CalculateSimilarty(k1,k2,error_tolerance=0.1):\n",
    "    \n",
    "    diff = k1  - k2\n",
    "    diff[diff<=error_tolerance]=0\n",
    "    \n",
    "    return (np.sum(diff==0) /(k1.shape[0]*k1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape:  (1, 128, 32, 32)\n",
      "\n",
      "number of feature map which has high similarty with a mean tensor :  19\n",
      "\n",
      "pruned tensor shape:  torch.Size([1, 109, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Make a random input tensor\n",
    "tensor = Variable(torch.randn(1,128,32,32))\n",
    "tensor = tensor.detach().numpy()\n",
    "print('input tensor shape: ', tensor.shape)\n",
    "\n",
    "# Make a inital zero tensor for a mean tensor\n",
    "t0 = np.zeros((tensor.shape[0], tensor.shape[1], tensor.shape[2], tensor.shape[3])) # (1,128,32,32)\n",
    "\n",
    "# Sum every value of each feature maps\n",
    "for i in range(tensor.shape[1]):\n",
    "    t0 += tensor[0][i]\n",
    "\n",
    "# Make a mean tensor\n",
    "mean_tensor = t0/tensor.shape[1]\n",
    "\n",
    "# Set the threshold (0~1)\n",
    "threshold = 0.7\n",
    "temp_sim_list = []\n",
    "where_sim_exceed_list = []\n",
    "\n",
    "# Calculate similarty between a mean tensor and each feature map tensors, with setted error tolerance\n",
    "for i in range(tensor.shape[1]):\n",
    "    t0 = tensor[0][i]\n",
    "    sim = CalculateSimilarty(t0, mean_tensor, error_tolerance=0.1)\n",
    "    temp_sim_list.append(sim)\n",
    "    \n",
    "# If similarty exceed the threshold, put the index of threshold in the empty list\n",
    "for i in range(tensor.shape[1]):\n",
    "    normalized_sim = (temp_sim_list[i] - min(temp_sim_list))/(max(temp_sim_list) - min(temp_sim_list))\n",
    "    if normalized_sim > threshold:\n",
    "        where_sim_exceed_list.append(i)\n",
    "\n",
    "print('\\nnumber of feature map which has high similarty with a mean tensor : ', len(where_sim_exceed_list))\n",
    "\n",
    "# Delete the feature map which has high similarty with a mean tensor\n",
    "pruned_tensor = np.delete(tensor, [index for index in where_sim_exceed_list], axis=1)\n",
    "\n",
    "# numpy array -> torch tensor\n",
    "pruned_tensor = torch.from_numpy(pruned_tensor)\n",
    "\n",
    "print('\\npruned tensor shape: ', pruned_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature map : 000, similarity: 0.7229\n",
      "feature map : 001, similarity: 0.3133\n",
      "feature map : 002, similarity: 0.3976\n",
      "feature map : 003, similarity: 0.3253\n",
      "feature map : 004, similarity: 0.3373\n",
      "feature map : 005, similarity: 0.4458\n",
      "feature map : 006, similarity: 0.5181\n",
      "feature map : 007, similarity: 0.4337\n",
      "feature map : 008, similarity: 0.8434\n",
      "feature map : 009, similarity: 0.4940\n",
      "feature map : 010, similarity: 0.9036\n",
      "feature map : 011, similarity: 0.7349\n",
      "feature map : 012, similarity: 0.4940\n",
      "feature map : 013, similarity: 0.7590\n",
      "feature map : 014, similarity: 0.4096\n",
      "feature map : 015, similarity: 0.5422\n",
      "feature map : 016, similarity: 0.5663\n",
      "feature map : 017, similarity: 0.5663\n",
      "feature map : 018, similarity: 0.4458\n",
      "feature map : 019, similarity: 0.5060\n",
      "feature map : 020, similarity: 0.7711\n",
      "feature map : 021, similarity: 0.3976\n",
      "feature map : 022, similarity: 0.6265\n",
      "feature map : 023, similarity: 0.9639\n",
      "feature map : 024, similarity: 0.3614\n",
      "feature map : 025, similarity: 0.5301\n",
      "feature map : 026, similarity: 0.5542\n",
      "feature map : 027, similarity: 0.6747\n",
      "feature map : 028, similarity: 0.3012\n",
      "feature map : 029, similarity: 0.3614\n",
      "feature map : 030, similarity: 0.5301\n",
      "feature map : 031, similarity: 0.3614\n",
      "feature map : 032, similarity: 0.7952\n",
      "feature map : 033, similarity: 0.6265\n",
      "feature map : 034, similarity: 0.3253\n",
      "feature map : 035, similarity: 0.4819\n",
      "feature map : 036, similarity: 0.5422\n",
      "feature map : 037, similarity: 0.3253\n",
      "feature map : 038, similarity: 0.4819\n",
      "feature map : 039, similarity: 0.0000\n",
      "feature map : 040, similarity: 0.5301\n",
      "feature map : 041, similarity: 0.5663\n",
      "feature map : 042, similarity: 0.3614\n",
      "feature map : 043, similarity: 0.1446\n",
      "feature map : 044, similarity: 0.3012\n",
      "feature map : 045, similarity: 0.4458\n",
      "feature map : 046, similarity: 0.4217\n",
      "feature map : 047, similarity: 0.5663\n",
      "feature map : 048, similarity: 0.9036\n",
      "feature map : 049, similarity: 0.5542\n",
      "feature map : 050, similarity: 0.3012\n",
      "feature map : 051, similarity: 0.6024\n",
      "feature map : 052, similarity: 0.5060\n",
      "feature map : 053, similarity: 0.5422\n",
      "feature map : 054, similarity: 0.6145\n",
      "feature map : 055, similarity: 0.3735\n",
      "feature map : 056, similarity: 0.5422\n",
      "feature map : 057, similarity: 0.0723\n",
      "feature map : 058, similarity: 0.4819\n",
      "feature map : 059, similarity: 0.4337\n",
      "feature map : 060, similarity: 0.3855\n",
      "feature map : 061, similarity: 0.2410\n",
      "feature map : 062, similarity: 0.3012\n",
      "feature map : 063, similarity: 0.4337\n",
      "feature map : 064, similarity: 0.4578\n",
      "feature map : 065, similarity: 0.6386\n",
      "feature map : 066, similarity: 0.6747\n",
      "feature map : 067, similarity: 0.5904\n",
      "feature map : 068, similarity: 0.5663\n",
      "feature map : 069, similarity: 0.5542\n",
      "feature map : 070, similarity: 0.4578\n",
      "feature map : 071, similarity: 0.6988\n",
      "feature map : 072, similarity: 0.2410\n",
      "feature map : 073, similarity: 0.4819\n",
      "feature map : 074, similarity: 0.6024\n",
      "feature map : 075, similarity: 0.2651\n",
      "feature map : 076, similarity: 0.3494\n",
      "feature map : 077, similarity: 0.2169\n",
      "feature map : 078, similarity: 0.4699\n",
      "feature map : 079, similarity: 0.6386\n",
      "feature map : 080, similarity: 0.2771\n",
      "feature map : 081, similarity: 0.4819\n",
      "feature map : 082, similarity: 0.5181\n",
      "feature map : 083, similarity: 0.4458\n",
      "feature map : 084, similarity: 0.4458\n",
      "feature map : 085, similarity: 0.5783\n",
      "feature map : 086, similarity: 0.5301\n",
      "feature map : 087, similarity: 0.7229\n",
      "feature map : 088, similarity: 0.6627\n",
      "feature map : 089, similarity: 0.7952\n",
      "feature map : 090, similarity: 0.2289\n",
      "feature map : 091, similarity: 0.4819\n",
      "feature map : 092, similarity: 0.7590\n",
      "feature map : 093, similarity: 0.5663\n",
      "feature map : 094, similarity: 0.4096\n",
      "feature map : 095, similarity: 0.5301\n",
      "feature map : 096, similarity: 0.3133\n",
      "feature map : 097, similarity: 0.4337\n",
      "feature map : 098, similarity: 1.0000\n",
      "feature map : 099, similarity: 0.1928\n",
      "feature map : 100, similarity: 0.2892\n",
      "feature map : 101, similarity: 0.5301\n",
      "feature map : 102, similarity: 0.2530\n",
      "feature map : 103, similarity: 0.3976\n",
      "feature map : 104, similarity: 0.4578\n",
      "feature map : 105, similarity: 0.2048\n",
      "feature map : 106, similarity: 0.7952\n",
      "feature map : 107, similarity: 0.2048\n",
      "feature map : 108, similarity: 0.6145\n",
      "feature map : 109, similarity: 0.5542\n",
      "feature map : 110, similarity: 0.6627\n",
      "feature map : 111, similarity: 0.6386\n",
      "feature map : 112, similarity: 0.2289\n",
      "feature map : 113, similarity: 0.7470\n",
      "feature map : 114, similarity: 0.7349\n",
      "feature map : 115, similarity: 0.3614\n",
      "feature map : 116, similarity: 0.3494\n",
      "feature map : 117, similarity: 0.4217\n",
      "feature map : 118, similarity: 0.3253\n",
      "feature map : 119, similarity: 0.9880\n",
      "feature map : 120, similarity: 0.5542\n",
      "feature map : 121, similarity: 0.7349\n",
      "feature map : 122, similarity: 0.4578\n",
      "feature map : 123, similarity: 0.3494\n",
      "feature map : 124, similarity: 0.4940\n",
      "feature map : 125, similarity: 0.8313\n",
      "feature map : 126, similarity: 0.1687\n",
      "feature map : 127, similarity: 0.5663\n"
     ]
    }
   ],
   "source": [
    "# Print the normalized similarity between the feature map number of the tensor (to be pruned) and the mean tensor\n",
    "for i in range(tensor.shape[1]):\n",
    "    normalized_sim = (temp_sim_list[i] - min(temp_sim_list))/(max(temp_sim_list) - min(temp_sim_list))\n",
    "    print('feature map : %03d, similarity: %0.4f' % (i, normalized_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pruning function based on the above process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning(tensor, threshold, error_tolerance):\n",
    "    \n",
    "    tensor = tensor.detach().numpy()\n",
    "\n",
    "    t = np.zeros((tensor.shape[0], tensor.shape[1], tensor.shape[2], tensor.shape[3])) # (1,128,32,32)\n",
    "\n",
    "    for i in range(tensor.shape[1]):\n",
    "        t += tensor[0][i]\n",
    "\n",
    "    mean_tensor = t/tensor.shape[1]\n",
    "    \n",
    "    temp_sim_list = []\n",
    "    where_sim_exceed_list = []\n",
    "\n",
    "    for i in range(tensor.shape[1]):\n",
    "        t0 = tensor[0][i]\n",
    "        sim = CalculateSimilarty(t0, mean_tensor, error_tolerance)\n",
    "        temp_sim_list.append(sim)\n",
    "    \n",
    "    for i in range(tensor.shape[1]):\n",
    "        normalized_sim = (temp_sim_list[i] - min(temp_sim_list))/(max(temp_sim_list) - min(temp_sim_list))\n",
    "        if normalized_sim > threshold:\n",
    "            where_sim_exceed_list.append(i)\n",
    "\n",
    "    pruned_tensor = np.delete(tensor, [index for index in where_sim_exceed_list], axis=1)\n",
    "    pruned_tensor = torch.from_numpy(pruned_tensor)\n",
    "    \n",
    "    return pruned_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test tensor shape:  torch.Size([1, 128, 32, 32])\n",
      "pruned tensor shape:  torch.Size([1, 114, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = Variable(torch.randn(1,128,32,32))\n",
    "print('test tensor shape: ', test_tensor.shape)\n",
    "\n",
    "pruned_tensor = pruning(test_tensor, threshold=0.7, error_tolerance=0.9)\n",
    "print('pruned tensor shape: ', pruned_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.8276e-01, -3.2362e-01,  1.5856e-01,  ..., -4.5694e-02,\n",
       "           -2.4110e-01,  2.6615e-01],\n",
       "          [ 2.3591e+00,  5.8619e-02, -2.1951e+00,  ...,  5.1960e-01,\n",
       "            6.5440e-01, -3.0105e-01],\n",
       "          [ 7.5492e-01,  1.3746e+00,  7.2352e-01,  ...,  5.9667e-01,\n",
       "           -1.5843e+00,  9.7456e-01],\n",
       "          ...,\n",
       "          [-1.0756e+00, -4.4399e-01, -7.2137e-02,  ...,  7.0271e-01,\n",
       "           -1.7004e-01, -2.4777e-01],\n",
       "          [ 6.2031e-01,  1.1454e+00,  1.5474e+00,  ...,  8.2495e-01,\n",
       "           -9.2652e-01, -1.2143e+00],\n",
       "          [ 4.9259e-01, -4.5404e-01, -5.8627e-01,  ..., -3.5105e-01,\n",
       "            1.3708e+00,  2.6773e-01]],\n",
       "\n",
       "         [[ 1.2791e+00, -2.0823e-01,  2.7541e-01,  ..., -4.0371e-01,\n",
       "            4.0912e-01, -2.1592e-01],\n",
       "          [ 1.0990e-01, -2.3167e-01,  4.9143e-01,  ...,  6.7083e-01,\n",
       "            9.1086e-02, -4.9011e-02],\n",
       "          [ 1.1220e-01, -2.4509e-01, -2.3001e-01,  ...,  2.2945e+00,\n",
       "            7.3707e-01,  7.0211e-01],\n",
       "          ...,\n",
       "          [-3.6028e-01, -4.4410e-01, -2.0514e+00,  ...,  1.7587e-01,\n",
       "           -9.0948e-01,  8.9213e-01],\n",
       "          [-4.2463e-02, -1.3800e+00, -9.9517e-01,  ...,  3.3581e-01,\n",
       "            9.6606e-01, -2.0220e+00],\n",
       "          [-1.3039e+00,  5.2509e-01, -9.3109e-01,  ...,  3.9678e-01,\n",
       "            1.0621e+00,  2.5496e-03]],\n",
       "\n",
       "         [[ 1.4652e+00,  7.8499e-01, -2.7846e-01,  ..., -5.4162e-01,\n",
       "           -2.2779e+00, -8.8392e-01],\n",
       "          [-2.9894e-01, -8.5058e-01, -2.8190e-01,  ..., -1.6727e+00,\n",
       "            1.1806e+00, -1.0201e+00],\n",
       "          [-1.6563e+00,  4.9536e-01, -6.4232e-01,  ..., -4.0599e-01,\n",
       "           -7.8618e-02, -9.9517e-01],\n",
       "          ...,\n",
       "          [-1.7659e+00, -7.1986e-01,  1.5290e-01,  ..., -9.0639e-01,\n",
       "            1.6476e-01, -1.3467e+00],\n",
       "          [-1.7924e+00,  6.8205e-01,  2.5896e-01,  ..., -1.3213e+00,\n",
       "           -1.0041e+00,  1.4824e+00],\n",
       "          [ 2.2029e-01, -4.7190e-01,  1.2196e+00,  ..., -3.8196e-01,\n",
       "            7.5902e-01, -8.2755e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0718e+00, -1.6637e-01, -5.2273e-01,  ..., -6.8381e-01,\n",
       "            3.3391e-01, -5.5239e-01],\n",
       "          [ 5.2555e-01,  1.6832e-01,  1.7852e+00,  ..., -7.0444e-01,\n",
       "           -4.5994e-01, -1.1666e+00],\n",
       "          [ 5.1885e-01, -1.2796e+00, -1.3442e+00,  ..., -4.6924e-01,\n",
       "            1.5827e+00, -7.3451e-01],\n",
       "          ...,\n",
       "          [ 5.3814e-01,  6.1503e-01, -2.7134e-01,  ..., -8.9956e-01,\n",
       "           -9.1541e-01,  2.4476e+00],\n",
       "          [ 2.4198e-01, -1.7881e-02, -7.9974e-01,  ..., -1.1639e-01,\n",
       "           -7.9183e-01,  1.6258e-01],\n",
       "          [ 6.7893e-01, -2.1820e-01,  1.2932e+00,  ..., -6.9849e-01,\n",
       "            1.6572e+00, -2.3478e-01]],\n",
       "\n",
       "         [[ 8.3175e-02, -7.7903e-01,  9.7892e-01,  ...,  1.1950e-01,\n",
       "            2.1994e-01,  1.8240e+00],\n",
       "          [ 1.1203e+00, -6.0072e-01,  5.7240e-01,  ...,  4.0256e-01,\n",
       "            7.4217e-01, -9.5010e-01],\n",
       "          [-9.9928e-01, -3.3000e-02, -1.4111e+00,  ...,  1.3727e+00,\n",
       "           -5.3643e-01,  8.3554e-01],\n",
       "          ...,\n",
       "          [ 1.1640e+00,  1.4333e+00,  9.0343e-01,  ..., -4.4221e-01,\n",
       "            1.3535e+00, -3.3391e-01],\n",
       "          [-2.0701e-02,  6.5842e-01,  3.9992e-01,  ...,  2.4815e-01,\n",
       "           -1.4064e-01,  2.4619e-01],\n",
       "          [ 5.3362e-01,  7.5430e-01,  2.6191e-01,  ..., -1.1943e+00,\n",
       "            1.3406e+00, -6.0198e-01]],\n",
       "\n",
       "         [[ 1.3974e-01, -2.2691e+00, -1.4677e+00,  ...,  2.1368e-01,\n",
       "           -4.0459e-01,  1.9067e-01],\n",
       "          [ 1.5604e+00,  6.5080e-01,  7.7992e-01,  ...,  3.2673e-01,\n",
       "           -9.4138e-01,  5.1677e-01],\n",
       "          [ 6.1329e-01,  4.3749e-01,  1.1721e+00,  ...,  8.4010e-02,\n",
       "            1.3904e+00,  6.3590e-01],\n",
       "          ...,\n",
       "          [-9.8312e-01, -2.6124e+00, -6.4933e-01,  ...,  1.1135e+00,\n",
       "           -9.5539e-02,  1.2102e+00],\n",
       "          [-2.7184e+00,  1.9628e-02,  1.0488e+00,  ..., -1.8303e+00,\n",
       "            7.7084e-01, -1.9865e-01],\n",
       "          [ 4.1683e-01,  1.0732e+00, -1.6930e+00,  ...,  9.3993e-01,\n",
       "            9.5447e-01,  1.5582e+00]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying method on the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Standard(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Standard, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = self.conv1.out_channels, out_channels = 256, kernel_size = 3, stride = 1)\n",
    "        \n",
    "    def pruning(self, tensor, threshold, error_tolerance):\n",
    "    \n",
    "        tensor = tensor.detach().numpy()\n",
    "\n",
    "        t = np.zeros((tensor.shape[0], tensor.shape[1], tensor.shape[2], tensor.shape[3])) # (1,128,32,32)\n",
    "\n",
    "        for i in range(tensor.shape[1]):\n",
    "            t += tensor[0][i]\n",
    "\n",
    "        mean_tensor = t/tensor.shape[1]\n",
    "\n",
    "        temp_sim_list = []\n",
    "        where_sim_exceed_list = []\n",
    "\n",
    "        for i in range(tensor.shape[1]):\n",
    "            t0 = tensor[0][i]\n",
    "            sim = CalculateSimilarty(t0, mean_tensor, error_tolerance)\n",
    "            temp_sim_list.append(sim)\n",
    "\n",
    "        for i in range(tensor.shape[1]):\n",
    "            normalized_sim = (temp_sim_list[i] - min(temp_sim_list))/(max(temp_sim_list) - min(temp_sim_list))\n",
    "            if normalized_sim > threshold:\n",
    "                where_sim_exceed_list.append(i)\n",
    "\n",
    "        pruned_tensor = np.delete(tensor, [index for index in where_sim_exceed_list], axis=1)\n",
    "        pruned_tensor = torch.from_numpy(pruned_tensor)\n",
    "\n",
    "        return pruned_tensor\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pruning(self.conv1(x), threshold=0.7, error_tolerance=0.1)\n",
    "        #x = self.conv2(x) -> How??\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the output feature map's parameters after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 104, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "def what_is_size_of_tensor(net):\n",
    "    y = net(Variable(torch.randn(1,3,32,32)))\n",
    "    print(y.size())\n",
    "\n",
    "model = Standard()    \n",
    "what_is_size_of_tensor(model) # original output size = (1, 128, 32, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
